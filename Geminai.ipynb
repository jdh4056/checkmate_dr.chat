{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301eefa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key='AIzaSyCHcy8oO-XhjsLCTdzLB64t9XR01OanbpM')\n",
    "\n",
    "\n",
    "for m in client.models.list():\n",
    "  if 'embedContent' in m.supported_actions:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab9f7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "  def __call__(self, input: Documents) -> Embeddings:\n",
    "    EMBEDDING_MODEL_ID = \"models/embedding-001\"\n",
    "    title = \"Custom query\"\n",
    "    response = client.models.embed_content(\n",
    "        model=EMBEDDING_MODEL_ID,\n",
    "        contents=input,\n",
    "        config=types.EmbedContentConfig(\n",
    "          task_type=\"retrieval_document\",\n",
    "          title=title\n",
    "        )\n",
    "    )\n",
    "    # ëª¨ë“  ë¬¸ì„œì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
    "    return [e.values for e in response.embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "322eb3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eh589\\AppData\\Local\\Temp\\ipykernel_10176\\75548902.py:27: DeprecationWarning: The class GeminiEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
      "  embedding_function=GeminiEmbeddingFunction()\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#chroma_client.delete_collection(\"my_collection\")\n",
    "def preprocess_metadata(metadata):\n",
    "    new_metadata = {}\n",
    "    for k, v in metadata.items():\n",
    "        if isinstance(v, list):\n",
    "            new_metadata[k] = \", \".join(map(str, v))  # ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "        else:\n",
    "            new_metadata[k] = v\n",
    "    return new_metadata\n",
    "def batch_add(collection, documents, metadatas, ids, batch_size=100):\n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        batch_docs = documents[i:i+batch_size]\n",
    "        batch_metas = metadatas[i:i+batch_size]\n",
    "        batch_ids = ids[i:i+batch_size]\n",
    "        collection.add(\n",
    "            documents=batch_docs,\n",
    "            metadatas=batch_metas,\n",
    "            ids=batch_ids\n",
    "        )\n",
    "def create_chroma_db(json_data, name):\n",
    "    import chromadb\n",
    "\n",
    "    chroma_client = chromadb.Client()\n",
    "    db = chroma_client.create_collection(\n",
    "        name=name,\n",
    "        embedding_function=GeminiEmbeddingFunction()\n",
    "    )\n",
    "\n",
    "    # JSON ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸, ë©”íƒ€ë°ì´í„°, id ì¶”ì¶œ\n",
    "    documents = [item[\"text\"] for item in json_data]\n",
    "    metadatas = [preprocess_metadata(item[\"metadata\"]) for item in json_data]\n",
    "    ids = [str(i) for i in range(len(json_data))]\n",
    "    \n",
    "    batch_add(db, documents, metadatas, ids, batch_size=100)\n",
    "   \n",
    "    return db\n",
    "with open('disease_rag_with_metadata.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "db = create_chroma_db(data, \"my_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9cb907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  IDs                                          Documents  \\\n",
      "0   0  Fever, Fatigue, Difficulty Breathing ì¦ìƒì´ ìˆëŠ” ê²½ìš°...   \n",
      "1   1      Cough, Fatigue ì¦ìƒì´ ìˆëŠ” ê²½ìš° Common Coldì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.   \n",
      "2   2           Cough, Fatigue ì¦ìƒì´ ìˆëŠ” ê²½ìš° Eczemaì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.   \n",
      "\n",
      "                                          Embeddings  \n",
      "0  [ 3.16955782e-02 -4.14985903e-02 -4.31520194e-...  \n",
      "1  [ 7.59642050e-02 -6.42082170e-02 -7.00410604e-...  \n",
      "2  [ 6.10879771e-02 -5.23152687e-02 -7.92896152e-...  \n"
     ]
    }
   ],
   "source": [
    "sample_data = db.get(include=['documents', 'embeddings'])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"IDs\": sample_data['ids'][:3],\n",
    "    \"Documents\": sample_data['documents'][:3],\n",
    "    \"Embeddings\": [str(emb)[:50] + \"...\" for emb in sample_data['embeddings'][:3]]  # Truncate embeddings\n",
    "})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4861eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fever, Fatigue, Difficulty Breathing ì¦ìƒì´ ìˆëŠ” ê²½ìš° Asthmaì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "def get_relevant_passage(query, db):\n",
    "  passage = db.query(query_texts=[query], n_results=1)['documents'][0][0]\n",
    "  return passage\n",
    "# Perform embedding search\n",
    "passage = get_relevant_passage(\"Fever, Cough, Difficulty Breathing\", db)\n",
    "print(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c7eede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ë‹¹ì‹ ì€ ì˜í•™ ìƒë‹´ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.\n",
      "    ë‹¤ìŒì€ ì°¸ê³ í•  ì¦ìƒ ë°ì´í„°ì…ë‹ˆë‹¤:\n",
      "    QUESTION: 'ë‚˜ëŠ” ê°ê¸°ì™€ ìŠµì§„ì´ ìˆì–´'\n",
      "    PASSAGE: 'Fever, Fatigue, Difficulty Breathing ì¦ìƒì´ ìˆëŠ” ê²½ìš° Asthmaì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.'\n",
      "    ì´ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:\n",
      "    ANSWER:\n",
      "  \n",
      "ì£„ì†¡í•˜ì§€ë§Œ, ì œê³µëœ ì •ë³´ë§Œìœ¼ë¡œëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "*   ì‚¬ìš©ìëŠ” ê°ê¸°ì™€ ìŠµì§„ì´ ìˆë‹¤ê³  í–ˆìŠµë‹ˆë‹¤.\n",
      "*   ì œê³µëœ ì •ë³´ëŠ” ë°œì—´, í”¼ë¡œ, í˜¸í¡ ê³¤ë€ ì¦ìƒì´ ì²œì‹ì¼ ìˆ˜ ìˆë‹¤ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ë‘ ì •ë³´ëŠ” ì§ì ‘ì ì¸ ê´€ë ¨ì´ ì—†ì–´, ì–´ë–¤ ë‹µë³€ì„ ì œê³µí•´ì•¼ í• ì§€ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë” ì •í™•í•œ ë‹µë³€ì„ ìœ„í•´ì„œëŠ” ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "*   ê°ê¸°ë‚˜ ìŠµì§„ê³¼ ê´€ë ¨ëœ ì¶”ê°€ì ì¸ ì¦ìƒ ì •ë³´\n",
      "*   ì²œì‹ ê°€ëŠ¥ì„±ì— ëŒ€í•œ ì§ˆë¬¸ ì—¬ë¶€\n",
      "*   ì›í•˜ëŠ” ë‹µë³€ì˜ ì¢…ë¥˜ (ì˜ˆ: ìê°€ ì¹˜ë£Œ ë°©ë²•, ë³‘ì› ë°©ë¬¸ í•„ìš”ì„± ë“±)\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ì‚¬ìš©ìê°€ \"ê°ê¸°ì™€ ìŠµì§„ ë•Œë¬¸ì— ê¸°ì¹¨ì´ ì‹¬í•´ìš”\" ë¼ê³  ì§ˆë¬¸í–ˆë‹¤ë©´, \"ì œê³µëœ ì •ë³´ì— ë”°ë¥´ë©´ í˜¸í¡ ê³¤ë€ ì¦ìƒì´ ìˆëŠ” ê²½ìš° ì²œì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸°ì¹¨ì´ ì‹¬í•˜ê³  í˜¸í¡ì´ ë¶ˆí¸í•˜ë‹¤ë©´ ë³‘ì›ì„ ë°©ë¬¸í•˜ì—¬ ì§„ë£Œë¥¼ ë°›ì•„ë³´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\" ì™€ ê°™ì´ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_relevant_passage(query, db):\n",
    "  passage = db.query(query_texts=[query], n_results=1)['documents'][0][0]\n",
    "  return passage\n",
    "# Perform embedding search\n",
    "passage = get_relevant_passage(\"Fever, Cough, Difficulty Breathing\", db)\n",
    "print(passage)\n",
    "def make_prompt(query, relevant_passage):\n",
    "  escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "  prompt = (\"\"\"\n",
    "    ë‹¹ì‹ ì€ ì˜í•™ ìƒë‹´ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.\n",
    "    ë‹¤ìŒì€ ì°¸ê³ í•  ì¦ìƒ ë°ì´í„°ì…ë‹ˆë‹¤:\n",
    "    QUESTION: '{query}'\n",
    "    PASSAGE: '{relevant_passage}'\n",
    "    ì´ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:\n",
    "    ANSWER:\n",
    "  \"\"\").format(query=query, relevant_passage=escaped)\n",
    "  return prompt\n",
    "query = \"ë‚˜ëŠ” ê°ê¸°ì™€ ìŠµì§„ì´ ìˆì–´\"\n",
    "prompt = make_prompt(query, passage)\n",
    "print(prompt)\n",
    "MODEL_ID = \"gemini-2.0-flash\"  # @param [\"gemini-2.0-flash-lite\", \"gemini-2.0-flash\", \"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-05-06\"] {\"allow-input\": true, \"isTemplate\": true}\n",
    "answer = client.models.generate_content(\n",
    "    model = MODEL_ID,\n",
    "    contents = prompt\n",
    ")\n",
    "print(answer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Client\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# â–¶ï¸ ì„ë² ë”© ëª¨ë¸\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "class MyEmbeddingFunction:\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def __call__(self, input):\n",
    "        return self.model.encode(input).tolist()\n",
    "\n",
    "embedding_fn = MyEmbeddingFunction()\n",
    "\n",
    "# â–¶ï¸ Chroma client\n",
    "client = Client()\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"medical_rag\",\n",
    "    embedding_function=embedding_fn\n",
    ")\n",
    "\n",
    "# â–¶ï¸ ì‚¬ìš©ì ì§ˆì˜\n",
    "user_query = \"ê¸°ì¹¨ê³¼ í˜¸í¡ ê³¤ë€ì´ ìˆì–´ìš”\"\n",
    "\n",
    "# â–¶ï¸ ì§ˆì˜ ì„ë² ë”© ìƒì„±\n",
    "query_embedding = model.encode([user_query]).tolist()\n",
    "\n",
    "# â–¶ï¸ Chroma ê²€ìƒ‰\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding,\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "# â–¶ï¸ ê´€ë ¨ ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "relevant_texts = results['documents'][0]\n",
    "context = \"\\n\".join(relevant_texts)\n",
    "\n",
    "gmodel = genai.GenerativeModel(\"gemini-pro\")\n",
    "response = gmodel.generate_content(f\"\"\"\n",
    "ë‹¹ì‹ ì€ ì˜í•™ ìƒë‹´ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒì€ ì°¸ê³ í•  ì¦ìƒ ë°ì´í„°ì…ë‹ˆë‹¤:\n",
    "\n",
    "{context}\n",
    "\n",
    "ì´ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:\n",
    "{user_query}\n",
    "\"\"\")\n",
    "\n",
    "print(\"ğŸ¤– Gemini ì‘ë‹µ:\", response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
